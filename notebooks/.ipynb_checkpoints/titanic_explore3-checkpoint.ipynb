{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (0.23.4)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from sklearn) (0.20.1)\r\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.15.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/site-packages (0.81)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from xgboost) (1.1.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from xgboost) (1.15.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "import sklearn.preprocessing\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../data/train.csv\"\n",
    "test_file = \"../data/test.csv\"\n",
    "\n",
    "\n",
    "train_data_raw = pd.read_csv(train_file)\n",
    "test_data_raw = pd.read_csv(test_file)\n",
    "\n",
    "target = \"Survived\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### CLEAN DATA FUNC\n",
    "\n",
    "def clean_func(train_data):\n",
    "    \n",
    "    ## DO IMPUTATION \n",
    "    # FARE\n",
    "    imp_fare = Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "    imp_fare.fit(train_data[[\"Fare\"]])\n",
    "    train_data[[\"Fare\"]]=imp_fare.transform(train_data[[\"Fare\"]]).ravel() \n",
    "\n",
    "    # Age\n",
    "    imp=Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "    imp.fit(train_data[[\"Age\"]])\n",
    "    train_data[[\"Age\"]]=imp.transform(train_data[[\"Age\"]]).ravel() \n",
    "    \n",
    "    # Filna\n",
    "    train_data[\"Cabin\"] = train_data[\"Cabin\"].fillna(\"\")\n",
    "\n",
    "    \n",
    "    # one hot encoding\n",
    "    sex_features = pd.get_dummies(train_data[\"Sex\"])\n",
    "    embarked_features = pd.get_dummies(train_data[\"Embarked\"])\n",
    "    \n",
    "    # rename embarked features\n",
    "    embarked_features = embarked_features.rename(columns={'C': 'embarked_cobh'\n",
    "                                                        , 'Q': 'embark_queenstown'\n",
    "                                                        , 'S': 'embark_southampton'})\n",
    "\n",
    "    # Concat new features\n",
    "    train_data_extras = pd.concat([train_data,sex_features,embarked_features],axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # HACK - REMOVE T WHICH IS NOT IN TEST LIKELY ERRROR \n",
    "    cabin_letters = pd.get_dummies(train_data['Cabin'].map(lambda x: \"empty\" if len(x)==0 or x[0]==\"T\" else x[0]))\n",
    "\n",
    "#    cabin_letters = pd.get_dummies(train_data['Cabin'].map(lambda x: \"empty\" if len(x)==0 else x[0]))\n",
    "    cabin_letters.columns = [\"Cabin_letter_\"+i for i in cabin_letters.columns]\n",
    "    train_data_extras = pd.concat([train_data_extras,cabin_letters],axis=1)\n",
    "    \n",
    "\n",
    "    train_data_extras[\"Cabin_number\"] = train_data['Cabin'].map(lambda x: -99 if len(x)==0 else x.split(\" \")[0][1:]) \n",
    "\n",
    "    # ONLY RETURN NUMERIC COLUMNS \n",
    "    num_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64','uint8']\n",
    "    train_data_numerics = train_data_extras.select_dtypes(include=num_types)\n",
    "\n",
    "    return train_data_numerics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data_raw2 = clean_func(train_data_raw)\n",
    "train_data = train_data_raw2.iloc[:, train_data_raw2.columns != target]\n",
    "train_data_target = train_data_raw2[target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(train_data\n",
    "                              ,train_data_target\n",
    "                              ,test_size=0.3\n",
    "                              ,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "- logreg\n",
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty=\"l2\", dual=False, tol=0.0001, C=1.0\n",
    "                             , fit_intercept=True, intercept_scaling=1\n",
    "                             , class_weight=None, random_state=None\n",
    "                             , solver=\"liblinear\", max_iter=100\n",
    "                             , multi_class=\"ovr\", verbose=0\n",
    "                             , warm_start=False, n_jobs=1)\n",
    "\n",
    "log_reg.fit(X_train,Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8022388059701493"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(\n",
    "n_estimators=100\n",
    ")\n",
    "\n",
    "model_rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8125     0.79365079 0.90322581 0.83870968 0.77419355 0.77419355\n",
      " 0.83870968 0.79032258 0.82258065 0.91935484]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation RF\n",
    "\n",
    "scores = cross_val_score(model_rf, X_train, Y_train, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873134328358209"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf = model_rf.predict(X_test)\n",
    "metrics.accuracy_score(Y_test,pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_decision_tree = RandomForestClassifier(\n",
    "n_estimators=1\n",
    ")\n",
    "\n",
    "model_decision_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7611940298507462"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dt = model_decision_tree.predict(X_test)\n",
    "metrics.accuracy_score(Y_test,pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_gs = RandomForestClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': array([ 60,  80, 100]), 'min_samples_leaf': array([2, 3])}\n"
     ]
    }
   ],
   "source": [
    "# parmeter dict\n",
    "param_grid = dict(\n",
    "    n_estimators=np.arange(60,101,20)\n",
    "    , min_samples_leaf=np.arange(2,4,1)\n",
    "    #, criterion = [\"gini\",\"entropy\"]\n",
    "    #, max_features = np.arange(0.1,0.5,0.1)\n",
    ")\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(model_rf_gs,param_grid=param_grid,scoring = \"accuracy\", cv = 5)\n",
    "grid.fit(train_data, train_data_target)\n",
    "\"\"\n",
    "\n",
    "# model_rf.fit(train_data, train_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(grid)\n",
    "# for i in ['params',\"mean_train_score\",\"mean_test_score\"]:\n",
    "#     print(i)\n",
    "#     print(grid.cv_results_[i])\n",
    "#grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 3, 'n_estimators': 100}\n",
      "0.8294051627384961\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = XGBClassifier(max_depth=7, learning_rate=0.01, n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=20,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8860353130016051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8246268656716418"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_train,model_xgboost.predict(X_train)))\n",
    "metrics.accuracy_score(Y_test,model_xgboost.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on full data - can only use estimate from cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_gs = RandomForestClassifier(**grid.best_params_)\n",
    "model_rf_gs.fit(train_data,train_data_target)\n",
    "\"\"\n",
    "#print(**grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get params - lin reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26215011]\n",
      "PassengerId 0.00029856426747853105\n",
      "Pclass -0.6157323114906712\n",
      "Age -0.029056958218352053\n",
      "SibSp -0.25731193638503996\n",
      "Parch -0.0986820701570479\n",
      "Fare 0.004646482861005507\n",
      "female 1.9122376324485557\n",
      "male -0.6500875237127047\n",
      "embarked_cobh 0.7087607252880808\n",
      "embark_queenstown 0.4078246018643139\n",
      "embark_southampton 0.0764307554336727\n",
      "Cabin_letter_A -0.11837924313536839\n",
      "Cabin_letter_B 0.25698074917313823\n",
      "Cabin_letter_C -0.5684826793159974\n",
      "Cabin_letter_D 0.568167377683216\n",
      "Cabin_letter_E 1.2341450053378016\n",
      "Cabin_letter_F 0.7592509600922503\n",
      "Cabin_letter_G -0.5403264963611312\n",
      "Cabin_letter_empty -0.3292055647380383\n"
     ]
    }
   ],
   "source": [
    "# get parameters\n",
    "coef = list(log_reg.coef_.ravel())\n",
    "intercept = log_reg.intercept_\n",
    "\n",
    "# print them\n",
    "print(intercept)\n",
    "\n",
    "coef\n",
    "for id, i in enumerate(coef):\n",
    "    print(train_data.columns[id],i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT AND STORE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### HACK TO COMPUTE TEST RESULT\n",
    "test_data = clean_func(test_data_raw)\n",
    "\n",
    "#test_data[[\"Age\"]]=imp.transform(test_data[[\"Age\"]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO IMPUTATION ON FARE\n",
    "# imp_fare = Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "# imp_fare.fit(train_data[[\"Fare\"]])\n",
    "\n",
    "# test_data[[\"Fare\"]]=imp_fare.transform(test_data[[\"Fare\"]]).ravel() # what is ravel???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0\n",
       "Pclass                0\n",
       "Age                   0\n",
       "SibSp                 0\n",
       "Parch                 0\n",
       "Fare                  0\n",
       "female                0\n",
       "male                  0\n",
       "embarked_cobh         0\n",
       "embark_queenstown     0\n",
       "embark_southampton    0\n",
       "Cabin_letter_A        0\n",
       "Cabin_letter_B        0\n",
       "Cabin_letter_C        0\n",
       "Cabin_letter_D        0\n",
       "Cabin_letter_E        0\n",
       "Cabin_letter_F        0\n",
       "Cabin_letter_G        0\n",
       "Cabin_letter_empty    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_y = log_reg.predict(test_data)\n",
    "test_data_y = log_reg.predict(test_data)\n",
    "\n",
    "\n",
    "#train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(list(zip(list(test_data[\"PassengerId\"]),list(test_data_y))))\n",
    "\n",
    "output.columns = [\"PassengerId\",\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(index=False, path_or_buf= \"../data/output.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output of random forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(data,file_name):\n",
    "    output = pd.DataFrame(list(zip(list(test_data[\"PassengerId\"]),list(data))))\n",
    "    output.columns = [\"PassengerId\",\"Survived\"]\n",
    "    output.to_csv(index=False, path_or_buf= \"../data/{file_name}.csv\".format(file_name=file_name))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =list(test_data.columns)\n",
    "b = list(train_data.columns)\n",
    "\n",
    "[item for item in b if item not in a]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_data_y = model_rf.predict(test_data)\n",
    "\n",
    "output(model_rf_data_y,\"predict_rf_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_gs_data_y =model_rf_gs.predict(test_data)\n",
    "output(model_rf_gs_data_y,\"predict_rf_gs_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost_data_y = model_xgboost.predict(test_data)\n",
    "output(model_xgboost_data_y,\"predict_xgboost_1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to add noise and different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_rf_gs\n",
    ",model_rf\n",
    ",model_xgboost\n",
    ",model_decision_tree]\n",
    "\n",
    "\n",
    "\n",
    "#pred_dt = model_decision_tree.predict(X_test)\n",
    "#metrics.accuracy_score(Y_test,pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId             int64\n",
       "Pclass                  int64\n",
       "Age                   float64\n",
       "SibSp                   int64\n",
       "Parch                   int64\n",
       "Fare                  float64\n",
       "female                  uint8\n",
       "male                    uint8\n",
       "embarked_cobh           uint8\n",
       "embark_queenstown       uint8\n",
       "embark_southampton      uint8\n",
       "Cabin_letter_A          uint8\n",
       "Cabin_letter_B          uint8\n",
       "Cabin_letter_C          uint8\n",
       "Cabin_letter_D          uint8\n",
       "Cabin_letter_E          uint8\n",
       "Cabin_letter_F          uint8\n",
       "Cabin_letter_G          uint8\n",
       "Cabin_letter_empty      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.normal(10,10)\n",
    "\n",
    "#X_test.shape[0]\n",
    "\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noise = X_test.copy()\n",
    "\n",
    "\n",
    "scale = list(range(0,20))\n",
    "acc = scale.copy()\n",
    "\n",
    "for i,s in enumerate(scale):\n",
    "    X_test_noise = X_test.copy()\n",
    "    X_test_noise[\"Age\"] = X_test_noise[\"Age\"] + np.ravel(np.random.normal(loc=0.0, scale=s, size=[X_test.shape[0],1]))\n",
    "    acc[i] = metrics.accuracy_score(Y_test, models[0].predict(X_test_noise))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
